# Curate adapter models

**Issue:** #3
**Submitted by:** @YinuoYang327
**Closed on:** 2025-12-15
**Labels:** None

---

1. ericrisco/medical-gemma-3n-lora (https://huggingface.co/ericrisco/medical-gemma-3n-lora): Efficient LoRA adapters for fine-tuning Gemma-3N-4B into a specialized emergency medical assistant. These lightweight adapters (76.9MB) transform the base model into a medical expert while maintaining the original model's general capabilities.
2. agnihotri‑anxh/HealthMate‑gemma‑medical‑lora (https://huggingface.co/agnihotri-anxh/HealthMate-gemma-medical-lora): HealthMate is a fine-tuned LoRA adapter built on Google Gemma-2B-IT, trained on medically-oriented text extracted from the Gale Encyclopedia of Medicine.
3. shibing624/ziya-llama-13b-medical-lora (https://huggingface.co/shibing624/ziya-llama-13b-medical-lora)
4. bootscoder/Llama-3-Medical-8B-CPT-lora (https://huggingface.co/bootscoder/Llama-3-Medical-8B-CPT-lora)：Continuous Pre-training (CPT) LoRA Adapter for Medical Chatbot Based on LLaMA-3.1-8B.
5. morvinp/medical-llama-lora-adapter (http://huggingface.co/morvinp/medical-llama-lora-adapter): This is a LoRA (Low-Rank Adaptation) adapter for medical conversations, trained on the LLaMA-7B model.
6. dsuram/mistral‑7B‑Medical‑QA‑LoRA (https://huggingface.co/dsuram/mistral-mental-health-lora): This model is a LoRA fine-tuned version of [mistralai/Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) designed to classify mental health-related statements
7. CodCodingCode/DeepSeek‑V2‑medical (https://huggingface.co/CodCodingCode/DeepSeek-V2-medical): This repository contains a 4-bit LoRA adapter fine-tuned on top of [deepseek-ai/DeepSeek-V2-Lite](https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite) for medical treatment planning.
8. AbdullahAlnemr1/qwen2.5‑medical‑lora (https://huggingface.co/AbdullahAlnemr1/qwen2.5-medical-lora): It is designed to generate medically relevant responses to user instructions, offering clear and concise health guidance.
9. TachyHealthResearch/medgemma-4b‑medical‑coding (https://huggingface.co/TachyHealthResearch/medgemma-4b-medical-coding): Base Model: medGemma4BFine-tuning Method: LoRA 
10. agnihotri-anxh/HealthMate-gemma-medical-lora (https://huggingface.co/agnihotri-anxh/HealthMate-gemma-medical-lora): HealthMate is a fine-tuned LoRA adapter built on Google Gemma-2B-IT, trained on medically-oriented text extracted from the Gale Encyclopedia of Medicine.
11. Tierney/DeepSeek-R1-Medical-Doctor-LoRA (https://huggingface.co/Tierney/DeepSeek-R1-Medical-Doctor-LoRA?utm_source=chatgpt.com): This LoRA adapter is fine-tuned based on DeepSeek-R1-Distill-Qwen-14B, primarily optimizing question-answering and reasoning capabilities in the medical domain.
12. jinv2/Qwen1.5-7B-Chat-LoRA-Medical-Rhinitis-Urticaria (https://huggingface.co/jinv2/Qwen1.5-7B-Chat-LoRA-Medical-Rhinitis-Urticaria?utm_source=chatgpt.com): This is a LoRA adapter ONLY. It MUST be used in conjunction with the original Qwen/Qwen1.5-7B-Chat base model.
13. sabber/medphi-medical-qa-adapter (https://huggingface.co/sabber/medphi-medical-qa-adapter): This is a LoRA adapter fine-tuned on Microsoft's [MediPhi-Instruct](https://huggingface.co/microsoft/MediPhi-Instruct) for medical question-answering. The model is designed to provide comprehensive, accurate answers to questions about medical diseases, conditions, and health-related topics.
14. nmitchko/medfalcon-40b-lora (https://huggingface.co/nmitchko/medfalcon-40b-lora): nmitchko/medfalcon-40b-lora is a large language model LoRa specifically fine-tuned for medical domain tasks.
15. Adilbai/medical-qa-t5-lora (https://huggingface.co/Adilbai/medical-qa-t5-lora): This model is a fine-tuned version of Google's T5 (Text-to-Text Transfer Transformer) optimized for medical question-answering tasks using Low-Rank Adaptation (LoRA) technique. 
16. MightyOctopus/qwen3-0.6B-lora-medical (https://huggingface.co/MightyOctopus/qwen3-0.6B-lora-medical): This model is a LoRA-fine-tuned version of [Qwen/Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B) using the dataset [Rabe3/QA_Synthetic_Medical_data](https://huggingface.co/datasets/Rabe3/QA_Synthetic_Medical_data).
17. zjudai/flowertune-medical-lora-qwen2.5-7b-instruct (https://huggingface.co/zjudai/flowertune-medical-lora-qwen2.5-7b-instruct): This is a LoRA adapter for Qwen/Qwen2.5-7B-Instruct fine-tuned with Flower federated learning framework on medical NLP datasets.
18. Arushp1/llama3-medquad-qlora (https://huggingface.co/Arushp1/llama3-medquad-qlora): This model is a fine-tuned version of LLaMA-3 8B Instruct using QLoRA (4-bit quantization + LoRA adapters) on the MedQuad Medical QnA Dataset.
19. 10mabdulmoid/deepseek-medical-lora (https://huggingface.co/10mabdulmoid/deepseek-medical-lora): A LoRA-finetuned variant of DeepSeek-Medical for medical QA and summarization tasks.
20. ZhangQiao123/medgemma-27b-it-chinese-medical-qa-lora (https://huggingface.co/ZhangQiao123/medgemma-27b-it-chinese-medical-qa-lora): Professional Chinese Medical QA AI Model

---

_Auto-generated from [Issue #3](https://github.com/justlab-ai/task/issues/3)_
